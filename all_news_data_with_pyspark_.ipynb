{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "all news data with pyspark .ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "o4gJ047dxirg"
      },
      "source": [
        "!apt-get install openjdk-8-jdk-headless -qq > /dev/null\n",
        "!wget -q https://downloads.apache.org/spark/spark-3.1.1/spark-3.1.1-bin-hadoop2.7.tgz\n",
        "!tar xf spark-3.1.1-bin-hadoop2.7.tgz\n",
        "!pip install -q findspark"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TFIjxWfmxipH"
      },
      "source": [
        "import os\n",
        "os.environ[\"JAVA_HOME\"] = \"/usr/lib/jvm/java-8-openjdk-amd64\"\n",
        "os.environ[\"SPARK_HOME\"] = \"/content/spark-3.1.1-bin-hadoop2.7\""
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "an9v3Q-Nxil0"
      },
      "source": [
        "\n",
        "import findspark\n",
        "findspark.init()\n",
        "from pyspark.sql import SparkSession\n",
        "spark = SparkSession.builder.master(\"local[*]\").getOrCreate()"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XE2IRxyRxikP"
      },
      "source": [
        "from pyspark.sql import SparkSession"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "veTexPbExiV9"
      },
      "source": [
        "spark = SparkSession.builder.getOrCreate()\n"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SU8GLMfZx7pr"
      },
      "source": [
        "from pyspark.sql import SparkSession\n",
        "from pyspark.sql.functions import udf, col, lower, regexp_replace,concat,lit,split\n",
        "from pyspark.ml.feature import Tokenizer, StopWordsRemover\n",
        "import nltk\n",
        "import string\n",
        "import re\n",
        "from nltk.stem.snowball import SnowballStemmer \n",
        "from pyspark.sql.functions import udf\n",
        "import pyspark.sql.types as T\n",
        "import pyspark.sql.functions as F\n",
        "from nltk import pos_tag\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "from nltk.corpus import stopwords\n",
        "from spacy.lang.en.stop_words import STOP_WORDS\n",
        "from itertools import filterfalse\n",
        "from nltk.corpus import wordnet as wn"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z80I2TDQyFe9",
        "outputId": "99d9803c-b46b-456c-c72a-72238b858f10"
      },
      "source": [
        "import nltk\n",
        "nltk.download('punkt')"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h0uToISLyNdy"
      },
      "source": [
        "!wget -q !wget  https://www.dropbox.com/s/cn2utnr5ipathhh/all-the-news-2-1.zip?dl=0"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yPDD36GoyNZC",
        "outputId": "54402818-d160-4598-be79-ccf905c4ed7d"
      },
      "source": [
        "! unzip /content/all-the-news-2-1.zip?dl=0.1"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Archive:  /content/all-the-news-2-1.zip?dl=0.1\n",
            "  inflating: all-the-news-2-1.csv    \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M745n_WnyJhK"
      },
      "source": [
        "data= spark.read.csv(\"/content/all-the-news-2-1.csv\",header=True,inferSchema=True)"
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UvMMKlaGyMl7"
      },
      "source": [
        "new_data=data.select(data.columns[7:])"
      ],
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nxVq61JB2hXQ"
      },
      "source": [
        "from pyspark.sql.functions import col,split,udf"
      ],
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lt3ZW4Km2j2F"
      },
      "source": [
        "final_data=new_data.drop(col(\"url\"))"
      ],
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nJA9izSu2mEi",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c2a75cdc-5fb2-483c-d91f-566f66191444"
      },
      "source": [
        "final_data.show()"
      ],
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "+--------------------+--------------------+--------------------+--------------------+\n",
            "|               title|             article|             section|         publication|\n",
            "+--------------------+--------------------+--------------------+--------------------+\n",
            "|We should take co...|\"This post is par...| several critics ...|         for example|\n",
            "|Colts GM Ryan Gri...| The Indianapolis...|                null|                null|\n",
            "|                null|                null|                null|                null|\n",
            "|Trump denies repo...|DAVOS, Switzerlan...|               Davos|             Reuters|\n",
            "|France's Sarkozy ...|PARIS (Reuters) -...|          World News|             Reuters|\n",
            "|Paris Hilton: Wom...|\"Paris Hilton arr...|                null|                 TMZ|\n",
            "|ECB's Coeure: If ...|BERLIN, June 17 (...|                null|                null|\n",
            "|                null|                null|                null|                null|\n",
            "|Venezuela detains...|CARACAS (Reuters)...|          World News|             Reuters|\n",
            "|You Can Trick You...|\"If only every da...| paying attention...| it makes it easi...|\n",
            "|How to watch the ...|Google I/O, the c...|                null|                 Vox|\n",
            "|China is dismissi...|China is dismissi...|                null|           Vice News|\n",
            "|“Elizabeth Warren...|Elizabeth Warren ...|                null|                 Vox|\n",
            "|Hudson's Bay's ch...|(Reuters) - The s...|       Business News|             Reuters|\n",
            "|Joakim Noah's Vic...|Joakim Noah's ﻿mo...|                null|                 TMZ|\n",
            "|Jermaine Jackson ...|\"Jermaine Jackson...| and the 2 will f...| Quincy isn't say...|\n",
            "|UK PM May presses...|LONDON (Reuters) ...|          World News|             Reuters|\n",
            "|Nancy Pelosi says...|\"Nancy Pelosi is ...|           of course| but it begins lo...|\n",
            "|The government of...|The nonpartisan d...|                null|                 Vox|\n",
            "|Mark Zuckerberg’s...|The threat of gov...|                null|                 Vox|\n",
            "+--------------------+--------------------+--------------------+--------------------+\n",
            "only showing top 20 rows\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K3cMiM0f29aj"
      },
      "source": [
        "from pyspark.sql import SparkSession\n",
        "from pyspark.sql.functions import udf, col, lower, regexp_replace\n",
        "from pyspark.ml.feature import Tokenizer, StopWordsRemover\n",
        "from nltk.stem.snowball import SnowballStemmer"
      ],
      "execution_count": 49,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HggSBaCf3B3B"
      },
      "source": [
        "from pyspark.sql.functions import lower,col,regexp_extract,filter,explode"
      ],
      "execution_count": 50,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_jErboO93FW1"
      },
      "source": [
        "import pyspark.sql.types as T\n",
        "import pyspark.sql.functions as F \n",
        "from pyspark.sql.functions import split\n"
      ],
      "execution_count": 51,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jMne8JBPa9s1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "68074210-9b50-4248-d51f-b063ced44271"
      },
      "source": [
        "def clean_text(c): ##cleaning text using clean_text function\n",
        "  c = lower(c)\n",
        "  c = regexp_replace(c, \"^rt \", \"\")\n",
        "  c = regexp_replace(c, \"(https?\\://)\\S+\", \"\")\n",
        "  c = regexp_replace(c, \"[^a-zA-Z0-9\\\\s]\", \"\")\n",
        "  return c\n",
        "\n",
        "clean_text_df = final_data.select(clean_text(col(\"article\")).alias(\"text\"))\n",
        "\n",
        "clean_text_df.printSchema()\n",
        "clean_text_df.show(10)"
      ],
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "root\n",
            " |-- text: string (nullable = true)\n",
            "\n",
            "+--------------------+\n",
            "|                text|\n",
            "+--------------------+\n",
            "|this post is part...|\n",
            "| the indianapolis...|\n",
            "|                null|\n",
            "|davos switzerland...|\n",
            "|paris reuters  fo...|\n",
            "|paris hilton arri...|\n",
            "|berlin june 17 re...|\n",
            "|                null|\n",
            "|caracas reuters  ...|\n",
            "|if only every day...|\n",
            "+--------------------+\n",
            "only showing top 10 rows\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wfJILAKm3KS5"
      },
      "source": [
        "@udf(returnType=T.ArrayType(T.StringType())) #create UDF function for tokenizeing data\n",
        "def word_tokenize(x):\n",
        "  if x == None:\n",
        "    return \"\"\n",
        "  else:\n",
        "    return nltk.word_tokenize(x)"
      ],
      "execution_count": 53,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Gegd4Xb_3M50"
      },
      "source": [
        "tokenize_data=clean_text_df.select(word_tokenize(F.col(\"text\")).alias(\"text\"))"
      ],
      "execution_count": 54,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sQRdZyVu3Oz1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4465d755-2084-49ed-a980-b48851feb3ba"
      },
      "source": [
        "tokenize_data.show()"
      ],
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "+--------------------+\n",
            "|                text|\n",
            "+--------------------+\n",
            "|[this, post, is, ...|\n",
            "|[the, indianapoli...|\n",
            "|                null|\n",
            "|[davos, switzerla...|\n",
            "|[paris, reuters, ...|\n",
            "|[paris, hilton, a...|\n",
            "|[berlin, june, 17...|\n",
            "|                null|\n",
            "|[caracas, reuters...|\n",
            "|[if, only, every,...|\n",
            "|[google, io, the,...|\n",
            "|[china, is, dismi...|\n",
            "|[elizabeth, warre...|\n",
            "|[reuters, the, su...|\n",
            "|[joakim, noahs, m...|\n",
            "|[jermaine, jackso...|\n",
            "|[london, reuters,...|\n",
            "|[nancy, pelosi, i...|\n",
            "|[the, nonpartisan...|\n",
            "|[the, threat, of,...|\n",
            "+--------------------+\n",
            "only showing top 20 rows\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HoZOWzRJ3U2f"
      },
      "source": [
        "tokens = tokenize_data.select(explode(col(\"text\")).alias(\"tokens\"))"
      ],
      "execution_count": 56,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "49u0_lD7331v",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9f5da02b-6e14-422c-94ce-45125f8a195e"
      },
      "source": [
        "tokens.show()"
      ],
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "+-----------+\n",
            "|     tokens|\n",
            "+-----------+\n",
            "|       this|\n",
            "|       post|\n",
            "|         is|\n",
            "|       part|\n",
            "|         of|\n",
            "|  polyarchy|\n",
            "|         an|\n",
            "|independent|\n",
            "|       blog|\n",
            "|   produced|\n",
            "|         by|\n",
            "|        the|\n",
            "|  political|\n",
            "|     reform|\n",
            "|    program|\n",
            "|         at|\n",
            "|        new|\n",
            "|    america|\n",
            "|          a|\n",
            "| washington|\n",
            "+-----------+\n",
            "only showing top 20 rows\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ITr82JT06ENM",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "59a1c5a5-6731-40b6-ccc1-f63e5246245e"
      },
      "source": [
        "from pyspark.ml.feature import Tokenizer\n",
        "\n",
        "tokenizer = Tokenizer(inputCol=\"tokens\", outputCol=\"vector\")\n",
        "vector_df = tokenizer.transform(tokens).select(\"vector\")\n",
        "\n",
        "vector_df.printSchema()\n",
        "vector_df.show(10)"
      ],
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "root\n",
            " |-- vector: array (nullable = true)\n",
            " |    |-- element: string (containsNull = true)\n",
            "\n",
            "+-------------+\n",
            "|       vector|\n",
            "+-------------+\n",
            "|       [this]|\n",
            "|       [post]|\n",
            "|         [is]|\n",
            "|       [part]|\n",
            "|         [of]|\n",
            "|  [polyarchy]|\n",
            "|         [an]|\n",
            "|[independent]|\n",
            "|       [blog]|\n",
            "|   [produced]|\n",
            "+-------------+\n",
            "only showing top 10 rows\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_T_676lK6iQu",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "011474fe-d7d3-4e5e-ef75-217c4eadcc94"
      },
      "source": [
        "remover = StopWordsRemover()\n",
        "stopwords = remover.getStopWords() \n",
        "\n",
        "# Display default list\n",
        "stopwords[:10]"
      ],
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['i', 'me', 'my', 'myself', 'we', 'our', 'ours', 'ourselves', 'you', 'your']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 59
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VKsiOPDS6spZ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d9f290e6-f8f9-4013-c44f-0dfd95c17261"
      },
      "source": [
        "# Specify input/output columns\n",
        "remover.setInputCol(\"vector\")\n",
        "remover.setOutputCol(\"vector_no_stopw\")\n",
        "\n",
        "# Transform existing dataframe with the StopWordsRemover\n",
        "vector_no_stopw_df = remover.transform(vector_df).select(\"vector_no_stopw\")\n",
        "\n",
        "# Display\n",
        "vector_no_stopw_df.printSchema()\n",
        "vector_no_stopw_df.show()"
      ],
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "root\n",
            " |-- vector_no_stopw: array (nullable = true)\n",
            " |    |-- element: string (containsNull = true)\n",
            "\n",
            "+---------------+\n",
            "|vector_no_stopw|\n",
            "+---------------+\n",
            "|             []|\n",
            "|         [post]|\n",
            "|             []|\n",
            "|         [part]|\n",
            "|             []|\n",
            "|    [polyarchy]|\n",
            "|             []|\n",
            "|  [independent]|\n",
            "|         [blog]|\n",
            "|     [produced]|\n",
            "|             []|\n",
            "|             []|\n",
            "|    [political]|\n",
            "|       [reform]|\n",
            "|      [program]|\n",
            "|             []|\n",
            "|          [new]|\n",
            "|      [america]|\n",
            "|             []|\n",
            "|   [washington]|\n",
            "+---------------+\n",
            "only showing top 20 rows\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DJIcL37b_q0O"
      },
      "source": [
        "# Import stemmer library\n",
        "from nltk.stem.porter import *\n",
        "stemmer = PorterStemmer()"
      ],
      "execution_count": 61,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YD-KZamQ_qvP"
      },
      "source": [
        "# Create stemmer python function\n",
        "def stem(in_vec):\n",
        "    out_vec = []\n",
        "    for t in in_vec:\n",
        "        t_stem = stemmer.stem(t)\n",
        "        if len(t_stem) > 2:\n",
        "            out_vec.append(t_stem)       \n",
        "    return out_vec"
      ],
      "execution_count": 62,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8S96ADZI_qtS"
      },
      "source": [
        "# Create user defined function for stemming with return type Array<String>\n",
        "from pyspark.sql.types import *\n",
        "stemmer_udf = udf(lambda x: stem(x), ArrayType(StringType()))"
      ],
      "execution_count": 63,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ud-0ePu5_qgj"
      },
      "source": [
        "# Create new df with vectors containing the stemmed tokens \n",
        "vector_stemmed_df = (\n",
        "    vector_no_stopw_df\n",
        "        .withColumn(\"vector_stemmed\", stemmer_udf(\"vector_no_stopw\"))\n",
        "        .select(\"vector_stemmed\")\n",
        "  )\n",
        "\n",
        "# Rename df and column for clarity\n",
        "production_df = vector_stemmed_df.select(col(\"vector_stemmed\").alias(\"bow\"))"
      ],
      "execution_count": 64,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GXRj2dqcADbK",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "39e8977a-fcd8-43cc-f1e4-c42080a8c3ac"
      },
      "source": [
        "# Display\n",
        "production_df.printSchema()\n",
        "production_df.show()"
      ],
      "execution_count": 65,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "root\n",
            " |-- bow: array (nullable = true)\n",
            " |    |-- element: string (containsNull = true)\n",
            "\n",
            "+------------+\n",
            "|         bow|\n",
            "+------------+\n",
            "|          []|\n",
            "|      [post]|\n",
            "|          []|\n",
            "|      [part]|\n",
            "|          []|\n",
            "| [polyarchi]|\n",
            "|          []|\n",
            "|  [independ]|\n",
            "|      [blog]|\n",
            "|    [produc]|\n",
            "|          []|\n",
            "|          []|\n",
            "|     [polit]|\n",
            "|    [reform]|\n",
            "|   [program]|\n",
            "|          []|\n",
            "|       [new]|\n",
            "|   [america]|\n",
            "|          []|\n",
            "|[washington]|\n",
            "+------------+\n",
            "only showing top 20 rows\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n6Fp3huM64JB"
      },
      "source": [
        "token_groups = production_df.groupby(col(\"bow\"))"
      ],
      "execution_count": 73,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f9r4nvrN7Ejf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b4cc9bea-7e8e-402e-9886-61a50b55325a"
      },
      "source": [
        "token_groups"
      ],
      "execution_count": 74,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<pyspark.sql.group.GroupedData at 0x7f4a107ed850>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 74
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4p9oLOlU8EUS"
      },
      "source": [
        "token_count =token_groups.count()"
      ],
      "execution_count": 75,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VtHAYEXnkJ1X"
      },
      "source": [
        "BOW_vector=token_count.orderBy(\"count\",ascending=False)"
      ],
      "execution_count": 76,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UvGH91Mcc5jt",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "091ce470-31a2-40f9-f472-5079df4d56ed"
      },
      "source": [
        "BOW=BOW_vector.show(50)  ##create Bag Of Word"
      ],
      "execution_count": 77,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "+----------+---------+\n",
            "|       bow|    count|\n",
            "+----------+---------+\n",
            "|        []|393234370|\n",
            "|    [said]|  4931937|\n",
            "|    [year]|  2436739|\n",
            "|     [new]|  2276717|\n",
            "|     [one]|  2099003|\n",
            "|   [trump]|  2013837|\n",
            "|    [like]|  1917987|\n",
            "|  [report]|  1781822|\n",
            "|    [time]|  1726524|\n",
            "|   [peopl]|  1701317|\n",
            "|    [also]|  1700307|\n",
            "| [compani]|  1687898|\n",
            "|   [state]|  1581131|\n",
            "|     [say]|  1517079|\n",
            "|  [presid]|  1334749|\n",
            "|   [first]|  1288641|\n",
            "| [percent]|  1278291|\n",
            "|    [make]|  1275585|\n",
            "|    [last]|  1264809|\n",
            "|    [work]|  1231943|\n",
            "|     [two]|  1211942|\n",
            "|     [get]|  1194458|\n",
            "|     [use]|  1133500|\n",
            "| [million]|  1127297|\n",
            "|  [reuter]|  1111078|\n",
            "|     [day]|  1000896|\n",
            "|  [includ]|   996050|\n",
            "|    [even]|   940189|\n",
            "|    [week]|   938312|\n",
            "|    [take]|   936473|\n",
            "|  [govern]|   913370|\n",
            "|    [show]|   912158|\n",
            "|    [want]|   879192|\n",
            "|    [call]|   875449|\n",
            "|    [back]|   864204|\n",
            "|    [hous]|   858504|\n",
            "|     [may]|   855749|\n",
            "| [countri]|   841240|\n",
            "|   [month]|   839748|\n",
            "|    [come]|   837678|\n",
            "|  [market]|   837673|\n",
            "|     [way]|   814681|\n",
            "|   [world]|   812852|\n",
            "|    [mani]|   812534|\n",
            "|    [told]|   788004|\n",
            "|[democrat]|   780835|\n",
            "|    [unit]|   780331|\n",
            "|    [sinc]|   772639|\n",
            "|   [share]|   769833|\n",
            "|  [nation]|   767998|\n",
            "+----------+---------+\n",
            "only showing top 50 rows\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}